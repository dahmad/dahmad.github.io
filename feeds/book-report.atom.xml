<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Donnie Ahmad - Book Report</title><link href="/" rel="alternate"></link><link href="/feeds/book-report.atom.xml" rel="self"></link><id>/</id><updated>2018-12-14T18:21:00-07:00</updated><entry><title>Notes on a JMLR Paper</title><link href="/notes-on-a-jmlr-paper.html" rel="alternate"></link><published>2018-12-14T18:21:00-07:00</published><updated>2018-12-14T18:21:00-07:00</updated><author><name>Donnie Ahmad</name></author><id>tag:None,2018-12-14:/notes-on-a-jmlr-paper.html</id><summary type="html">&lt;h1&gt;Numerical Anaylsis near Singularities in RBF Networks&lt;/h1&gt;
&lt;p&gt;Follow along with the source material &lt;a href="http://www.jmlr.org/papers/volume19/16-210/16-210.pdf"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. The parameter space of most learning machines have singular regions where the Fisher information matrices degenerate.&lt;/strong&gt;
* A parameter space is the set of all possible combinations of values for all parameters in a model. &lt;a href="https://en.wikipedia.org/wiki/Parameter_space"&gt;(src …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Numerical Anaylsis near Singularities in RBF Networks&lt;/h1&gt;
&lt;p&gt;Follow along with the source material &lt;a href="http://www.jmlr.org/papers/volume19/16-210/16-210.pdf"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. The parameter space of most learning machines have singular regions where the Fisher information matrices degenerate.&lt;/strong&gt;
* A parameter space is the set of all possible combinations of values for all parameters in a model. &lt;a href="https://en.wikipedia.org/wiki/Parameter_space"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A parameter differs from a variable in a model in that they tend to represent inherent properties of a system. &lt;a href="https://en.wikipedia.org/wiki/Parameter"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learning machine examples provided in the paper and brief explanations&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Layered neural networks: used to define a complex, non-linear form of hypotheses using "neurons" that have their input and output mapped through operations called activation functions. &lt;a href="http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Normal mixtures: where the joint probability of two random variables is normally distributed. &lt;a href="https://www.jmp.com/support/help/14/normal-mixtures.shtml"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Binomial mixtures&lt;/li&gt;
&lt;li&gt;Bayes networks: represents variables and their "conditional dependencies" in an ordered graphical model. &lt;a href="https://en.wikipedia.org/wiki/Bayesian_network"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hidden Markov models: a Markov process in an unobserved space. &lt;a href="https://en.wikipedia.org/wiki/Hidden_Markov_Models"&gt;(src)&lt;/a&gt; A Markov chain describes a sequence of events in which the current event relies entirely on the position the previous event created. &lt;a href="https://en.wikipedia.org/wiki/Markov_chain"&gt;(src)&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Boltzmann machines: a type of stochastic recurrent neural network. &lt;a href="https://en.wikipedia.org/wiki/Boltzmann_machine"&gt;(src)&lt;/a&gt; Stochastic neural networks use random variations to help escape local minima in optimization problems. &lt;a href="https://en.wikipedia.org/wiki/Stochastic_neural_network"&gt;(src)&lt;/a&gt; Recurrent neural networks are where connections between nodes form a directed graph along a sequence. &lt;a href="https://en.wikipedia.org/wiki/Recurrent_neural_network"&gt;(src)&lt;/a&gt; A directed graph differs from an undirected graph in that the nodes (or edges) are ordered. &lt;a href="https://en.wikipedia.org/wiki/Directed_graph"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stochastic context-free grammars: a set of rules that describe all possible strings in a language. &lt;a href="https://en.wikipedia.org/wiki/Context-free_grammar"&gt;(src)&lt;/a&gt; As noted above, stochastic refers to the introduced randomness.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A singular region is where a mathematical object is undefined or where the function "misbehaves." A simple example is that f(x) = 1/x has a singularity at x = 0. [(src)](https://en.wikipedia.org/wiki/Singularity_(mathematics)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fisher information is a measurement of how much information a random variable has about an unknown parameter. &lt;a href="https://en.wikipedia.org/wiki/Fisher_information"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A matrix "degenerates" in that it becomes a singular matrix. Degenerate and singular matrices are defined as not having an inverse. &lt;a href="https://math.stackexchange.com/questions/792587/what-is-the-difference-between-singular-matrices-and-degenerate-matrices"&gt;(src)&lt;/a&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What this sentence means in its entirety is currently a mystery to me.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Learning dynamics are slowed and trapped in plateaus by singularities in the case of feedforward neural networks.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Learning dynamics? Perhaps some numerical measure of how a model acts?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Feedforward neural networks? An artificial neural network where connections between nodes do not form a cycle. &lt;a href="https://en.wikipedia.org/wiki/Feedforward_neural_network"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. The criteria used to select a model and the standard paradigm described by the Cramer-Rao theorem both fail at singularities.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Model selection techniques mentioned and brief explanations&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Akaike Information Criterion: estimates the amount of information lost from using a given model to describe some process. &lt;a href="https://en.wikipedia.org/wiki/Akaike_information_criterion"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bayes Information Criterion: based on the likelihood function but penalizes model complexity. &lt;a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion"&gt;(src)&lt;/a&gt;. Likelihood is a measure of the likelihood of one value given another &lt;a href="https://en.wikipedia.org/wiki/Likelihood_function"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Minimum Description Length: comparable to Occam's razor. &lt;a href="https://en.wikipedia.org/wiki/Minimum_description_length"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cramer Rao theorem: describes estimators of a deterministic but unknown parameter. Relates to Fisher information. &lt;a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. A selection tool that accounts for singularities is the widely applicable Bayesian information criteria (WBIC), which was used to solve the Gaussian process regression case.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;WBIC: A generalized version of the afore-described BIC that can be calculated even without knowing the true distribution of the underlying data. &lt;a href="https://en.wikipedia.org/wiki/Watanabe–Akaike_information_criterion"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gaussian process regression case: A Gaussian process is a collection of random variables where every combination of the values is normally distributed. This specific tool is used to infer continuous values. It is also known as kriging. &lt;a href="https://en.wikipedia.org/wiki/Gaussian_process"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;5. The error function is a viable alternative to the traditional log-sigmoid function to understand the learning dynamics for multilayer perceptrons (MLPs).&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Error function: if Y is normally distributed with mean 0 and variance 1/2, the error function of x is the probability that Y falls in the range [-x, x] &lt;a href="https://en.wikipedia.org/wiki/Error_function"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Log-sigmoid function: a logistic curve with an S shape. To solve the equation at a given point, we subtract the midpoint x from our current value of x. We then multiply this value by steepness of the curve. We raise e to the inverse of this product and add 1. Finally, we divide the maximum value of the curve by everything. &lt;a href="https://en.wikipedia.org/wiki/Logistic_function"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A multilayer perceptron is a feedforward ANN with at least three layers: input, hidden, and output. The latter two of these use a nonlinear activition function. MLPs use backpropagation for training. &lt;a href="https://en.wikipedia.org/wiki/Multilayer_perceptron"&gt;(src)&lt;/a&gt; An explanation of backpropogation will follow under sentence 8.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;6. The averaged learning equations, the learning dynamics near overlap singularities, and mechanism of plateau phenomena near singularities are presently being studied for radial basis functions, which are a type of feedforward neural networks.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I could not find a solid definition of averaged learning equations or learning dynamics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overlap singularities are described later in this paper.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A radial basis function is one whose value depends on Euclidean distance from the origin. All values must be real. The sums of these functions can be interpreted as a simple kind of neural network. &lt;a href="https://en.wikipedia.org/wiki/Radial_basis_function"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;7. The &lt;em&gt;natural gradient method&lt;/em&gt; is a proposed solution to the problem that standard gradient methods are not &lt;em&gt;Fisher efficient&lt;/em&gt; and the gradient descent is not steep enough when there are singularities.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Gradient descent: an optimization algorithm for finding the minimum of a funciton ([src])(https://en.wikipedia.org/wiki/Gradient_descent)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Natural gradient method: further reading required &lt;a href="https://wiseodd.github.io/techblog/2018/03/14/natural-gradient/"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fisher efficiency: a function that finds the minimum possible variance for an unbiased estimator divided by its actual variance &lt;a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;8. The difficulty of training deep neural networks using Backpropagation is that it is computationally expensive and presents vanishing gradient problems.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Backpropagation: a method to calculate a gradient which furthermore is used to calculate weights. It uses the chain rule to iteratively computer gradient for each layer &lt;a href="https://en.wikipedia.org/wiki/Backpropagation"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Gradient: a vector value (as opposed to the scalar value) representing the rate of change of multiple variables &lt;a href="https://en.wikipedia.org/wiki/Gradient"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Chain rule: a formula for computing derivatives where two or more functions are composed into one &lt;a href="https://en.wikipedia.org/wiki/Chain_rule"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Vanishing gradient problem: weights being updated by the partial derivative of the error function fail to update as the gradient value gets smaller &lt;a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;9. One proposed solution is a deep belief network which multilayer Boltzmann machines which are trained layer-by-layer in a greedy fashion.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Deep belief network: a generative graphical model with latent variables contained within connected layers &lt;a href="https://en.wikipedia.org/wiki/Deep_belief_network"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;generative model: contrast to discriminative model; models the joint probability distribution of an observable variable and the target variable &lt;a href="https://en.wikipedia.org/wiki/Generative_model"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;graphical model: a graph can express the "conditional dependence structure between random variables" &lt;a href="https://en.wikipedia.org/wiki/Graphical_model"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;latent variable: variables inferred not observed &lt;a href="https://en.wikipedia.org/wiki/Latent_variable"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multilayer Boltzmann machine: also called a deep Boltzmann machine &lt;a href="https://en.wikipedia.org/wiki/Boltzmann_machine"&gt;(src)&lt;/a&gt;; satisfies Markov properties &lt;a href="https://en.wikipedia.org/wiki/Markov_random_field"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Greediness (in algorithms): make locally optimimum choice, perhaps with intention of locating global optimimum or to simply converge on an acceptable answer in an acceptable time frame &lt;a href="https://en.wikipedia.org/wiki/Greedy_algorithm"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;10. "[The] robustness of the training effect [for deep neural networks] cannot be guaranteed, even with a pre-training process."&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Pre-training: rather than randomly assigning weights on the first run then optimizing later, start with the weights from a similar problem and optimize from there &lt;a href="https://stats.stackexchange.com/questions/193082/what-is-pre-training-a-neural-network"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;11. It is not clear why large models remain slow despite limited obstacles&lt;/h3&gt;
&lt;h3&gt;12. Saddle points may cause pain points.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Saddle points: orthogonal slopes of 0 give false appearance of being a local minimum or maximum &lt;a href="https://en.wikipedia.org/wiki/Saddle_point"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;13. Gradient descent can find a band of low critical points, which are local minima of "high quality."&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Critical point: when the derivative of a differentiable function equals 0 &lt;a href="https://en.wikipedia.org/wiki/Critical_point_(mathematics)"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;14. This paper contends that "points in the elimination singularity are saddles, the points in the overlap singularity are local minima . . . and the generalization error surface near the overlap singularity is very flat."&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Elimination singularities appear to be but are not local extrema&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overlap singularities are indicative of a local minima&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generalization error: how well the model performs on unseen data &lt;a href="https://en.wikipedia.org/wiki/Generalization_error"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;15. The error of deep linear neural networks does not change under a scaling transformation.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;scaling transformation: enlarge or shrink an object the same amount in all directions &lt;a href="https://en.wikipedia.org/wiki/Scaling_(geometry)"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;16. Scaling symmetries are similar to elimination singularities.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Scaling symmetries: similar to self-similarity and fractals &lt;a href="https://en.wikipedia.org/wiki/Scale_invariance"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;17. The learning dynamics of deep belief nets, deep convolutional neural networks, and deep multilayer perceptrons may be affected by singularities.&lt;/h3&gt;
&lt;h3&gt;18. Singularities are worth studying because of overfitting issues and to improve learning efficiency&lt;/h3&gt;
&lt;h3&gt;19. There are two types of singularities in the parameter space of RBF networks: overlap and elimination singularities.&lt;/h3&gt;
&lt;h3&gt;20. Dynamics near singularities are studied through simulation, and it is observed that the behavior is similar between RBF networks, multilayer perceptrons and Gaussian mixtures (and possibly other feedforward neural networks)&lt;/h3&gt;
&lt;h3&gt;21. An RBF Network with k hidden units is the function of x and theta where x is a point in a real coordinate space that denotes the input vector and theta represents all of the parameters of the model.&lt;/h3&gt;
&lt;h3&gt;22. The function equals the sum from 1 to k of the weight of the neuron times the Guassian function of x and J (the center vector for the neuron which is also a point in a real coordinate space).&lt;/h3&gt;
&lt;h3&gt;23. If two hidden units overlap, then the first weight times the Gaussian function of x and the first parameter plus the second weight times the Gaussian function of x and the second parameter equals the sum of the weights times the Gaussian function of x and the first parameter regardless of what the weights actually are.&lt;/h3&gt;
&lt;h3&gt;24. Therefore, w equals the sum of the two parameters even if you don't know the individual weights.&lt;/h3&gt;
&lt;h3&gt;25. An overlap singularity is the set of all parameters where the two center vectors are equal.&lt;/h3&gt;
&lt;h3&gt;26. An elimination singularity is the set of all parameters where the first weight equals zero.&lt;/h3&gt;
&lt;h3&gt;27. This paper explicitly describes the Fisher information matrix for the RBF network, uses average learning equations to examine RBF learning dynamics, and runs numerical simulations to see what happens near singularities.&lt;/h3&gt;
&lt;h3&gt;28. The Fisher information matrix is an indicator of a singularity.&lt;/h3&gt;
&lt;h3&gt;29. For regressions, an unknown teacher function generates y from x plus some additive noise.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;teacher function: could not find a definition&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;30. The training input has a Gaussian distribution and a covariance matrix.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Covariance matrix: an element at position i,j holds the covariance value for the i-th and j-th value of a random vector (variable with multiple dimensions) &lt;a href="https://en.wikipedia.org/wiki/Covariance_matrix"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;31. The covariance matrix does not change the analytical results so it can be set to the identity matrix.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;identity matrix: a matrix where the diagonal from upper left to bottom right has value 1 and the rest have value 0 &lt;a href="https://en.wikipedia.org/wiki/Identity_matrix"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;32. For RBFs, the Fisher information matrix is inner product of is the delta (partial derivative?) of the function of x and theta divided by the delta of theta for two points.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partial derivative: for a function with multiple variables, it is the derivative of one of those variables &lt;a href="https://en.wikipedia.org/wiki/Partial_derivative"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;33. This can be further expanded into a much larger matrix where the set of complex numbers Ji and Jj equal some multiplication involving a lower case sigma that I cannot parse.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A lot going on here that I don't understand. . . .&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lower case sigma could refer to standard deviation or the sigmoid function (defined above) &lt;a href="https://en.wikipedia.org/wiki/Sigma"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;34. Near singularities, the condition value of the matrix is large and its inverse is near zero.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Condition number: how much the output can change given a small change in the input &lt;a href="https://en.wikipedia.org/wiki/Condition_number"&gt;(src)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The inverse being near zero appears to mean that large changes in the input have no change on the output&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;35. So the inverse of the condition value can measure nearness to a singularity.&lt;/h3&gt;
&lt;h3&gt;36. Using the inverse of the Fisher information matrix as a weight overcomes the influence of singularities in the natural gradient descent method.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;"The Cramer-Rao bound states that the inverse of the Fisher information is a lower bound on the variance of any unbiased estimator of [theta]" &lt;a href="https://en.wikipedia.org/wiki/Fisher_information"&gt;(src)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;37. Obtaining the analytical form of the Fisher information matrix improves the natural gradient descent algorithms moving forward in addition to being fundamental to the following numerical analysis.&lt;/h3&gt;
&lt;h3&gt;38. Artificial experiments were analyzed for low and medium dimensioned examples given a known input distribution.&lt;/h3&gt;
&lt;h3&gt;39. Batch made learning dynamics are similar to those using the averaged learning equations.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Still can't grasp a clear defition of either learning dynamics or average learning equations, and now I can't find anything for batch mode&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;40. ALEs don't depend on specific data.&lt;/h3&gt;
&lt;h3&gt;41. ALEs are ordinary differential equations and can be solved to obtain student parameters.&lt;/h3&gt;
&lt;h3&gt;42. The function-naught of x equals the function of x theta-naught plus some Gaussian additive noise that is uncorrelated with training input x.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Gaussian noise: statistical noise that has a probability density function equal to the normal distribution &lt;a href=""&gt;(src)&lt;/a&gt; where the probability density function &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;43. Furthermore, this equals the sum of v times the Gaussian function of x and t plus that noise.&lt;/h3&gt;
&lt;h3&gt;44. The analytical form of ALEs is an extremely long equation that I am not prepared to understand. . .&lt;/h3&gt;
&lt;h3&gt;45. There is a generalized error equation defined here as well.&lt;/h3&gt;
&lt;h3&gt;46. Investigating a model with two hidden units is enough to capture thes essence.&lt;/h3&gt;
&lt;h3&gt;47. This can be compared to general cases of RBF networks; all of which is "obtained by solving ALEs for the given teacher parameters and initial student parameters."&lt;/h3&gt;
&lt;h3&gt;48. Analyzing a case where the teacher and student models have two hidden units.&lt;/h3&gt;
&lt;h3&gt;49. Lower-case sigma refers to the spread constant.&lt;/h3&gt;
&lt;h3&gt;50. Focus on an input x with dimension 1 because the global minimum is the point where generalization error is 0.&lt;/h3&gt;
&lt;h3&gt;51. Part of the student parameters are kept invariable in order to create 3D visuals.&lt;/h3&gt;
&lt;h3&gt;52. Two teacher model parameters are set to another initial parameter and only J1 and J2 are modified for overlap singularities.&lt;/h3&gt;
&lt;h3&gt;53. A different set of weights are fixed in other cases.&lt;/h3&gt;
&lt;h3&gt;54. In general, these are only two variable parameters.&lt;/h3&gt;
&lt;h3&gt;55. Plotting learning trajectories is accomplished through the generalization error surface in a 3D figure.&lt;/h3&gt;
&lt;h3&gt;56. Choosing only one teacher function is done to illustrate that RBF networks can be affected by the singularities under different initial states.&lt;/h3&gt;</content></entry></feed>